# üå©Ô∏è ARQUITECTURA EN LA NUBE - MLOps NLP EN AWS

## ‚ú® Introducci√≥n

Esta arquitectura representa una soluci√≥n MLOps completa y escalable para el procesamiento de datos de texto (tweets) y la clasificaci√≥n autom√°tica en categor√≠as predefinidas mediante t√©cnicas de NLP y Machine Learning. Est√° implementada sobre servicios administrados de AWS, permitiendo trazabilidad, automatizaci√≥n, seguridad y eficiencia operativa. La soluci√≥n incluye flujos de entrenamiento, inferencia y evoluci√≥n del modelo.

---

## üóÇÔ∏è Descripci√≥n General de Componentes

### üì• 1. Ingesta y Almacenamiento Inicial

| Servicio       | Funci√≥n |
|----------------|--------|
| `S3 - Raw`     | Zona de aterrizaje para archivos JSON/CSV. Configurado con versionado y cifrado. |
| `AWS Lambda / AWS Glue` | Validaci√≥n del esquema, metadatos y calidad de los datos entrantes. |
| `AWS Glue Data Catalog` | Cat√°logo de metadatos de los datasets. |
| `S3 - Ingested` | Almac√©n de datos ya validados y enriquecidos. |

---

### üß† 2. Feature Engineering (NLP)

| Servicio       | Funci√≥n |
|----------------|--------|
| `AWS Batch / Fargate` | Ejecuta contenedores Docker con scripts Python (`data_prep`, `preprocessing`, `feature_engineering`). |
| `S3 - Processed` | Contenedor de los datos procesados, listos para clustering o entrenamiento. |
| `Athena`       | Exploraci√≥n interactiva y validaci√≥n de calidad de datos. |

---

### üß™ 3. Pseudo-Etiquetado (Clustering)

| Servicio       | Funci√≥n |
|----------------|--------|
| `AWS Batch`    | Ejecuta `clustering.py` (con KMeans, UMAP). |
| `S3 - Pseudo-Labeled` | Almacena los datos con pseudo-etiquetas generadas autom√°ticamente. |

---

### üéØ 4. Entrenamiento del Clasificador

| Servicio       | Funci√≥n |
|----------------|--------|
| `SageMaker Training Job` | Entrena un modelo de clasificaci√≥n basado en los datos pseudo-etiquetados. |
| `S3 - Model Artifacts`   | Guarda los modelos (.joblib, m√©tricas, etc.). |
| `SageMaker Model Registry` | Versiona, eval√∫a y aprueba modelos entrenados. |

---

### ü§ñ 5. Inferencia Batch

| Servicio       | Funci√≥n |
|----------------|--------|
| `S3 - New Data` | Nuevos lotes de datos para inferencia. |
| `SageMaker Batch Transform` | Ejecuta inferencia batch usando el modelo aprobado. |
| `S3 - Predictions` | Almacena las predicciones generadas. |
| `RDS / DynamoDB` | Bases de datos opcionales para consulta o dashboards. |

---

### üîÅ 6. Orquestaci√≥n y Monitoreo

| Servicio       | Funci√≥n |
|----------------|--------|
| `AWS Step Functions` | Orquesta cada etapa del pipeline (validaci√≥n, FE, clustering, entrenamiento, inferencia). |
| `Amazon CloudWatch` | Centraliza logs, m√©tricas y dashboards. |
| `EventBridge` | Dispara pipelines por cron o eventos (subida a S3, cambios en par√°metros, etc.). |

---

### üõ†Ô∏è 7. CI/CD y Seguridad

| Servicio       | Funci√≥n |
|----------------|--------|
| `CodeCommit / GitHub` | Repositorio de c√≥digo fuente (scripts, Dockerfiles, IaC). |
| `CodePipeline / GitHub Actions` | Automatiza testing, construcci√≥n de im√°genes y despliegue del pipeline. |
| `Amazon ECR`   | Registro de im√°genes Docker usadas por Batch/Fargate. |
| `AWS KMS, GuardDuty, Tags` | Seguridad, control de costos y protecci√≥n de artefactos y datos. |

---

### ‚ôªÔ∏è 8. Evoluci√≥n de Categor√≠as y Reentrenamiento

| Componente | Funci√≥n |
|------------|--------|
| `S3 - New Data for Clustering` | Acumulaci√≥n peri√≥dica de datos recientes no etiquetados. |
| `Exploratory Clustering Job (Batch)` | Genera un nuevo resumen de clusters para detectar nuevas posibles categor√≠as. |
| `Cluster Report + Summary (S3)` | Informe que debe ser validado por expertos. |
| `Validaci√≥n Humana (Lambda)` | Paso semiautomatizado donde el analista decide cambios en categor√≠as. |
| `Actualizar category_map()` | Cambia la l√≥gica de mapeo de clusters a etiquetas. |
| `Step Function - Reentrenamiento` | Ejecuta nuevo entrenamiento con el esquema de categor√≠as actualizado y despliega el modelo actualizado. |

---

## üìå Consideraciones T√©cnicas

- Todos los scripts se ejecutan en contenedores Docker para garantizar reproducibilidad.
- Los datos est√°n cifrados en reposo (SSE-KMS) y en tr√°nsito (TLS).
- El pipeline es **modular**, **escalable** y **versionado**, cumpliendo los principios clave de **MLOps**.
- El ciclo de vida del modelo est√° controlado por una combinaci√≥n de `SageMaker Model Registry`, `CodePipeline`, `Step Functions` y `CloudWatch`.

---

## üöÄ Conclusi√≥n

Esta arquitectura permite una gesti√≥n eficiente, escalable y segura del flujo de Machine Learning para procesamiento de lenguaje natural. Incorpora automatizaci√≥n, trazabilidad, versionamiento, monitoreo y adaptabilidad al cambio, lo que la hace ideal tanto para entornos de prueba t√©cnica como para entornos de producci√≥n real.
